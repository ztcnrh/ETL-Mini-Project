{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "threaded-crossing",
   "metadata": {},
   "source": [
    "# Extract #1\n",
    "<hr>\n",
    "The purpose of this notebook is to combine the series of separate book datasets gathered from Kaggle into one and filter out unwanted columns.\n",
    "\n",
    "This is one of the two datasets that will be utilized in the \"(T)ransformation\" step for the ETL project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cordless-destruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies and Setup\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "freelance-error",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File to Load\n",
    "dataset_one = \"../raw_datasets/book1-100k.csv\"\n",
    "dataset_two = \"../raw_datasets/book100k-200k.csv\"\n",
    "dataset_three = \"../raw_datasets/book200k-300k.csv\"\n",
    "dataset_four = \"../raw_datasets/book300k-400k.csv\"\n",
    "dataset_five = \"../raw_datasets/book400k-500k.csv\"\n",
    "dataset_six = \"../raw_datasets/book500k-600k.csv\"\n",
    "dataset_seven = \"../raw_datasets/book600k-700k.csv\"\n",
    "dataset_eight = \"../raw_datasets/book700k-800k.csv\"\n",
    "dataset_nine = \"../raw_datasets/book800k-900k.csv\"\n",
    "dataset_ten = \"../raw_datasets/book900k-1000k.csv\"\n",
    "dataset_eleven = \"../raw_datasets/book1000k-1100k.csv\"\n",
    "dataset_twelve = \"../raw_datasets/book1100k-1200k.csv\"\n",
    "dataset_thirteen = \"../raw_datasets/book1200k-1300k.csv\"\n",
    "dataset_fourteen = \"../raw_datasets/book1300k-1400k.csv\"\n",
    "dataset_fifteen = \"../raw_datasets/book1400k-1500k.csv\"\n",
    "dataset_sixteen = \"../raw_datasets/book1500k-1600k.csv\"\n",
    "dataset_seventeen = \"../raw_datasets/book1600k-1700k.csv\"\n",
    "dataset_eighteen = \"../raw_datasets/book1700k-1800k.csv\"\n",
    "dataset_nineteen = \"../raw_datasets/book1800k-1900k.csv\"\n",
    "dataset_twenty = \"../raw_datasets/book1900k-2000k.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "related-lender",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read book datasets and read as DataFrames\n",
    "df1 = pd.read_csv(dataset_one)\n",
    "df2 = pd.read_csv(dataset_two)\n",
    "df3 = pd.read_csv(dataset_three)\n",
    "df4 = pd.read_csv(dataset_four)\n",
    "df5 = pd.read_csv(dataset_five)\n",
    "df6 = pd.read_csv(dataset_six)\n",
    "df7 = pd.read_csv(dataset_seven)\n",
    "df8 = pd.read_csv(dataset_eight)\n",
    "df9 = pd.read_csv(dataset_nine)\n",
    "df10 = pd.read_csv(dataset_ten)\n",
    "df11 = pd.read_csv(dataset_eleven)\n",
    "df12 = pd.read_csv(dataset_twelve)\n",
    "df13 = pd.read_csv(dataset_thirteen)\n",
    "df14 = pd.read_csv(dataset_fourteen)\n",
    "df15 = pd.read_csv(dataset_fifteen)\n",
    "df16 = pd.read_csv(dataset_sixteen)\n",
    "df17 = pd.read_csv(dataset_seventeen)\n",
    "df18 = pd.read_csv(dataset_eighteen)\n",
    "df19 = pd.read_csv(dataset_nineteen)\n",
    "df20 = pd.read_csv(dataset_twenty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "laden-perth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine datasets into one\n",
    "combined_df = df1.append([df2, df3, df4, df5, df6, df7, df8, df9, df10,\\\n",
    "                          df11, df12, df13, df14, df15, df16, df17, df18, df19, df20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "present-alabama",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(917502, 21)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check number of rows\n",
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bronze-hughes",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create final dataset ready for next step\n",
    "final_df = combined_df[['ISBN', 'Name', 'Authors', 'Rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "proud-windsor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Name</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Harry Potter and the Half-Blood Prince (Harry ...</td>\n",
       "      <td>J.K. Rowling</td>\n",
       "      <td>4.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0439358078</td>\n",
       "      <td>Harry Potter and the Order of the Phoenix (Har...</td>\n",
       "      <td>J.K. Rowling</td>\n",
       "      <td>4.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Harry Potter and the Sorcerer's Stone (Harry P...</td>\n",
       "      <td>J.K. Rowling</td>\n",
       "      <td>4.47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ISBN                                               Name  \\\n",
       "0         NaN  Harry Potter and the Half-Blood Prince (Harry ...   \n",
       "1  0439358078  Harry Potter and the Order of the Phoenix (Har...   \n",
       "2         NaN  Harry Potter and the Sorcerer's Stone (Harry P...   \n",
       "\n",
       "        Authors  Rating  \n",
       "0  J.K. Rowling    4.57  \n",
       "1  J.K. Rowling    4.50  \n",
       "2  J.K. Rowling    4.47  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview data\n",
    "final_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "active-farmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export\n",
    "final_df.to_csv('../cleaned_datasets/source_kaggle.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "maritime-median",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData] *",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
